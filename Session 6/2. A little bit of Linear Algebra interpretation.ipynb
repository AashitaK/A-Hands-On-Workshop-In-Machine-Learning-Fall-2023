{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02fd1ae2",
   "metadata": {},
   "source": [
    "Recall:\n",
    "#### A linear transformation\n",
    "A linear transformation (or linear map) is a transformation $T:V \\to W$ satisfying \n",
    "\\begin{split} \n",
    "T(v_1+v_2) &= T(v_1)+T(v_2) \\\\\n",
    "T(cv) &= cT(v)\n",
    "\\end{split}\n",
    "for any vectors $v_1, v_2, v$ in $V$ and any scalar $c$.\n",
    "\n",
    "A linear transformation preserves the basic structure of the vector spaces, that is\n",
    "\n",
    "If \n",
    "\\begin{split} \n",
    "v_1 &\\to w_1\\\\ \n",
    "v_2 &\\to w_2\n",
    "\\end{split}\n",
    "\n",
    "then $$av_1+bv_2 \\to aw_1+bw_2$$\n",
    "\n",
    "for any vectors $v_1, v_2$ in $V$ and any scalars $a, b$.\n",
    "\n",
    "ADD Photo!!!!!!!!!!!!\n",
    "\n",
    "#### Basis vectors\n",
    "Basis vectors are a set of vectors that span the entire vector space. They are linearly independent, meaning that no basis vector can be written as a linear combination of the other basis vectors. \n",
    "\n",
    "For example, the following set of 6-dimensional identity vectors forms a basis.\n",
    "\n",
    "\\begin{split}\n",
    "e_1 &= [1, 0, 0, 0, 0, 0]\\\\\n",
    "e_2 &= [0, 1, 0, 0, 0, 0]\\\\\n",
    "e_3 &= [0, 0, 1, 0, 0, 0]\\\\\n",
    "e_4 &= [0, 0, 0, 1, 0, 0]\\\\\n",
    "e_5 &= [0, 0, 0, 0, 1, 0]\\\\\n",
    "e_6 &= [0, 0, 0, 0, 0, 1]\n",
    "\\end{split}\n",
    "\n",
    "Every vector in the vector space can be expressed uniquely as a linear combination of the basis vectors.\n",
    "\n",
    "For example, $$v = [2, 5, 0, 1, 0, 8] = 2e_1 + 5 e_2 + e_4 + 8e_6$$\n",
    "\n",
    "\n",
    "#### Matrices as linear transformations\n",
    "- ***Every matrix is a linear transformation but not all linear transformations are given by matrices.*** \n",
    "- ***For finite dimensional spaces, every linear transformation can be represented as a matrix once the sets of basis for both vector spaces are chosen.***\n",
    "\n",
    "\\begin{split}\n",
    "e_1 &= [1, 0, 0, 0, 0, 0]\\\\\n",
    "e_2 &= [0, 1, 0, 0, 0, 0]\\\\\n",
    "e_3 &= [0, 0, 1, 0, 0, 0]\\\\\n",
    "e_4 &= [0, 0, 0, 1, 0, 0]\\\\\n",
    "e_5 &= [0, 0, 0, 0, 1, 0]\\\\\n",
    "e_6 &= [0, 0, 0, 0, 0, 1]\n",
    "\\end{split}\n",
    "\n",
    "\\begin{split}\n",
    "f_1 &= [1, 0, 0]\\\\\n",
    "f_2 &= [0, 1, 0]\\\\\n",
    "f_3 &= [0, 0, 1]\\\\\n",
    "\\end{split}\n",
    "\n",
    "How do I come up with the matrix for linear transformation?\n",
    "\n",
    "If the linear transformation is mapping the basis vectors to the 3-dimensional space in the following way\n",
    "\n",
    "\\begin{split} \n",
    "e_1 &\\to [0.93, 0.91, 0.94]\\\\ \n",
    "e_2 &\\to [0.09, 0.77, 0.19]\\\\\n",
    "e_3 &\\to [0.9 , 0.06, 0.86]\\\\\n",
    "e_4 &\\to [0.08, 0.93, 0.05]\\\\\n",
    "e_5 &\\to [0.75, 0.09, 0.07]\\\\\n",
    "e_6 &\\to [0.05, 0.88, 0.95]\\\\\n",
    "\\end{split}\n",
    "\n",
    "then the matrix for linear transformation is given by\n",
    "\n",
    "\\begin{bmatrix}\n",
    "0.93 & 0.91 & 0.94\\\\\n",
    "0.09 & 0.77 & 0.19\\\\\n",
    "0.9 & 0.06 & 0.86\\\\\n",
    "0.08 & 0.93 & 0.05\\\\\n",
    "0.75 & 0.09 & 0.07\\\\\n",
    "0.05 & 0.88 & 0.95\\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02ea7e",
   "metadata": {},
   "source": [
    "### Neural networks\n",
    "\n",
    "As we are dealing with finite dimensional spaces in neural network architectures, the weighted sum operation in the forward propagation, that can be given by the matrices of weights connecting the two layers, are linear transformations. \n",
    "\n",
    "The application of activation functions makes the transformation non-linear. \n",
    "\n",
    "We learnt how the decision boundary for classification in logistic classifier was a linear hyperplane. When we apply a non-linear activation function such as sigmoid to the weighted sum expression, the resulting decision boundary is a manifold (understood in simple terms as a continuous, non-intersecting surface).\n",
    "\n",
    "This blog [Neural Networks, Manifolds, and Topology by Chris Olah](https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/) is an interesting read to understand neural networks in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53411b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
