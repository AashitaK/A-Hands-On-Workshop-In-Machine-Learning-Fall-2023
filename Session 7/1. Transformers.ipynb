{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edee1b13",
   "metadata": {},
   "source": [
    "In the original architecture, the encoder/decoder blocks are stacked on top of each other. Six blocks are used in the model trained in the paper but they can be any number. Though the six encoder blocks have the same structure, their weights are different that will be determined via the training process. The same is true for decoder blocks.\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png\" width=\"600\" />\n",
    "\n",
    "#### Encoder architecture\n",
    "<img  src=\"https://github.com/christianversloot/machine-learning-articles/raw/main/images/Diagram-3.png\" width=\"350\" />\n",
    "\n",
    "The encoder consists of \n",
    "* Input embedding\n",
    "* Positional encoding\n",
    "* Multi-head self-attention\n",
    "* Feedforward network\n",
    "\n",
    "**Residual connections** are used to bypass the complex blocks so that the gradients can flow freely in the backward direction. Add and Norm blocks are used to merged the residual connections with other blocks.\n",
    "\n",
    "##### Self-attention in transformers:\n",
    "The attention mechanism encodes the contextual information for a word in the sentence. For each word, attention scores w.r.t. other words in the sentence are calculated that corresponds to the importance of those words in understanding the current word.\n",
    "\n",
    "For example, the attention scores for \"it\" are visualized below from a trained transformer model. You can see how the attention score carry relevant contextual information.\n",
    "\n",
    "![](https://jalammar.github.io/images/t/transformer_self-attention_visualization.png)\n",
    "\n",
    "We will come back in the next class to understand attention mechanism in more detail by playing around the visualizations in this [BertViz Interactive Tutorial](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing)\n",
    "\n",
    "[BertViz repository](https://github.com/jessevig/bertviz) is an excellent resource for interactively visualizing attention in Transformer language models such as BERT, GPT2, or T5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47e7ac",
   "metadata": {},
   "source": [
    "#### Decoder architecture\n",
    "\n",
    "<img  src=\"https://github.com/christianversloot/machine-learning-articles/raw/main/images/Diagram-17-627x1024.png\" width=\"500\" />\n",
    "\n",
    "The decoder is similar to the encoder but it has an additional masked multi-head self-attention layer for the shifted output in which only the words prior to the current word can be seen and the later words in the output sequence are hidden by the mask.\n",
    "\n",
    "The decoder also has a final linear+softmax layer for generating the output probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3235d",
   "metadata": {},
   "source": [
    "#### Terminology\n",
    "* Embeddings\n",
    "* Cosine similarity\n",
    "* Context window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1971eea",
   "metadata": {},
   "source": [
    "#### Further reading\n",
    "* Reference textbook for deep learning: https://www.deeplearningbook.org\n",
    "* The Illustrated Transformers blog: https://jalammar.github.io/illustrated-transformer/\n",
    "* Sebastian Raschka has provided an excellent reading list for large language models: https://sebastianraschka.com/blog/2023/llm-reading-list.html\n",
    "\n",
    "#### Applications\n",
    "An excellent resource for learning the many applications of GPT models are the [example notebooks in OpenAI Cookbook](https://github.com/openai/openai-cookbook/tree/main/examples). This is a live repository which means that these notebooks are being updated frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f2f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
